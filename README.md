# Sign-Language-alphabets-detector

Demo:<a href="https://ashishks777.github.io/Sign-Language-alphabets-detector/">click here</a>

Building a neural network that can identify which letter of the Indian Sign Language (ISL) alphabet is being signed, given an input feed of a signing hand, is the purpose of this project. The project attempts to create a potential sign language translator that could translate sign language communications into written language. Such a translator would greatly lower the barrier for many deaf and mute individuals to be able to better communicate with others in day to day interactions.

Large barriers like  information deprivation, limitation of social connections, and difficulty integrating in society  stem from the communication disconnect between the deaf and the hearing, profoundly affecting the life quality of physically challenged citizens. Thus, our project aims to close the gap between those with physical impairments and normal citizens.

Most research implementations used till date for this task involve resource intensive implementations that have used depth maps generated by depth camera and high resolution images. The goal of this project was to test if neural networks are able to classify signed ISL letters using simple images of hands taken with a personal device such as a laptop webcam. This is consistent with the motivation since it would make a real-time ISL to written language translator implementation realistic in real-world settings.
